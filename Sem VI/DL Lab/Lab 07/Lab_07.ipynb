{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformation for Gaussian noise\n",
    "class Gaussian(object):\n",
    "    def __init__(self, mean: float, var: float):\n",
    "        self.mean = mean\n",
    "        self.var = var\n",
    "\n",
    "    def __call__(self, img: torch.Tensor) -> torch.Tensor:\n",
    "        return img + torch.normal(self.mean, self.var, img.size())\n",
    "\n",
    "preprocess_augmentation = T.Compose([\n",
    "    T.CenterCrop((224, 224)),\n",
    "    # T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomRotation(45),\n",
    "    Gaussian(0, 0.15),\n",
    "])\n",
    "\n",
    "preprocess_no_augmentation = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "# Dataset class\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, transform=None, str=\"train\"):\n",
    "        self.imgs_path = os.path.join(\"..\", \"Lab_06\", \"cats_and_dogs_filtered\", str)\n",
    "        file_list = glob.glob(os.path.join(self.imgs_path, \"*\"))\n",
    "        self.data = []\n",
    "        for class_path in file_list:\n",
    "            class_name = os.path.basename(class_path)\n",
    "            for img_path in glob.glob(os.path.join(class_path, \"*.jpg\")):\n",
    "                self.data.append([img_path, class_name])\n",
    "        self.class_map = {\"dogs\": 0, \"cats\": 1}\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, class_name = self.data[idx]\n",
    "        img = PIL.Image.open(img_path)\n",
    "        class_id = self.class_map[class_name]\n",
    "        class_id = torch.tensor(class_id)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, class_id\n",
    "\n",
    "# Train the model\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=10):\n",
    "    train_loader = dataloaders['train']\n",
    "    val_loader = dataloaders['val']\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch}/{num_epochs - 1}\")\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_preds += torch.sum(preds == labels)\n",
    "            total_preds += labels.size(0)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = correct_preds.double() / total_preds\n",
    "        print(f\"Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct_preds += torch.sum(preds == labels)\n",
    "                total_preds += labels.size(0)\n",
    "\n",
    "        val_acc = correct_preds.double() / total_preds\n",
    "        print(f\"Val Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "        # Deep copy the model\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_wts = model.state_dict()\n",
    "\n",
    "    print(f\"Best val Acc: {best_acc:.4f}\")\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "# CNN model definition\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(28*28*64, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Set device to CUDA if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create datasets with and without augmentation\n",
    "train_dataset_aug = MyDataset(transform=preprocess_augmentation, str=\"train\")\n",
    "train_dataset_no_aug = MyDataset(transform=preprocess_no_augmentation, str=\"train\")\n",
    "\n",
    "# Load datasets into DataLoader\n",
    "train_loader_aug = DataLoader(train_dataset_aug, batch_size=64, shuffle=True)\n",
    "train_loader_no_aug = DataLoader(train_dataset_no_aug, batch_size=64, shuffle=True)\n",
    "\n",
    "# Create validation dataset and dataloaders\n",
    "val_dataset = MyDataset(transform=preprocess_no_augmentation, str=\"validation\")\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "dataloaders_with_aug = {'train': train_loader_aug, 'val': val_loader}\n",
    "dataloaders_without_aug = {'train': train_loader_no_aug, 'val': val_loader}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Data Augmentation\n",
      "Epoch 0/9\n",
      "----------\n",
      "Train Loss: 0.8497 Acc: 0.4960\n",
      "Val Accuracy: 0.5020\n",
      "Epoch 1/9\n",
      "----------\n",
      "Train Loss: 0.6935 Acc: 0.5000\n",
      "Val Accuracy: 0.5000\n",
      "Epoch 2/9\n",
      "----------\n",
      "Train Loss: 0.6933 Acc: 0.5000\n",
      "Val Accuracy: 0.5000\n",
      "Epoch 3/9\n",
      "----------\n",
      "Train Loss: 0.6935 Acc: 0.5045\n",
      "Val Accuracy: 0.5010\n",
      "Epoch 4/9\n",
      "----------\n",
      "Train Loss: 0.6929 Acc: 0.5185\n",
      "Val Accuracy: 0.5540\n",
      "Epoch 5/9\n",
      "----------\n",
      "Train Loss: 0.6918 Acc: 0.5195\n",
      "Val Accuracy: 0.5000\n",
      "Epoch 6/9\n",
      "----------\n",
      "Train Loss: 0.6978 Acc: 0.5175\n",
      "Val Accuracy: 0.5000\n",
      "Epoch 7/9\n",
      "----------\n",
      "Train Loss: 0.6926 Acc: 0.5135\n",
      "Val Accuracy: 0.5140\n",
      "Epoch 8/9\n",
      "----------\n",
      "Train Loss: 0.6897 Acc: 0.5445\n",
      "Val Accuracy: 0.5420\n",
      "Epoch 9/9\n",
      "----------\n",
      "Train Loss: 0.6929 Acc: 0.5120\n",
      "Val Accuracy: 0.5000\n",
      "Best val Acc: 0.5540\n"
     ]
    }
   ],
   "source": [
    "# Model, Loss function, and Optimizer\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train model with data augmentation\n",
    "print(\"Training with Data Augmentation\")\n",
    "model_with_aug = train_model(model, dataloaders_with_aug, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training without Data Augmentation\n",
      "Epoch 0/9\n",
      "----------\n",
      "Train Loss: 0.8585 Acc: 0.4980\n",
      "Val Accuracy: 0.5000\n",
      "Epoch 1/9\n",
      "----------\n",
      "Train Loss: 0.6913 Acc: 0.5235\n",
      "Val Accuracy: 0.5070\n",
      "Epoch 2/9\n",
      "----------\n",
      "Train Loss: 0.6796 Acc: 0.5680\n",
      "Val Accuracy: 0.6620\n",
      "Epoch 3/9\n",
      "----------\n",
      "Train Loss: 0.6461 Acc: 0.6300\n",
      "Val Accuracy: 0.6650\n",
      "Epoch 4/9\n",
      "----------\n",
      "Train Loss: 0.5854 Acc: 0.7000\n",
      "Val Accuracy: 0.6750\n",
      "Epoch 5/9\n",
      "----------\n",
      "Train Loss: 0.5809 Acc: 0.7050\n",
      "Val Accuracy: 0.7070\n",
      "Epoch 6/9\n",
      "----------\n",
      "Train Loss: 0.4947 Acc: 0.7605\n",
      "Val Accuracy: 0.6760\n",
      "Epoch 7/9\n",
      "----------\n",
      "Train Loss: 0.4744 Acc: 0.7720\n",
      "Val Accuracy: 0.7030\n",
      "Epoch 8/9\n",
      "----------\n",
      "Train Loss: 0.3626 Acc: 0.8475\n",
      "Val Accuracy: 0.7080\n",
      "Epoch 9/9\n",
      "----------\n",
      "Train Loss: 0.2987 Acc: 0.8780\n",
      "Val Accuracy: 0.7220\n",
      "Best val Acc: 0.7220\n"
     ]
    }
   ],
   "source": [
    "# Model, Loss function, and Optimizer\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train model without data augmentation\n",
    "print(\"\\nTraining without Data Augmentation\")\n",
    "model_without_aug = train_model(model, dataloaders_without_aug, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1\n",
    "L2 Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 Regularization using loop to find L2 norm of weights\n",
    "def l2_regularization(model, lambda_l2=0.01):\n",
    "    l2_norm = 0.0\n",
    "    for param in model.parameters():\n",
    "        l2_norm += torch.norm(param, 2) ** 2  # L2 norm squared\n",
    "    return lambda_l2 * l2_norm\n",
    "\n",
    "# Modified train_model function to include L2 regularization manually\n",
    "def train_model_with_l2_regularization(model, dataloaders, criterion, optimizer, num_epochs=10, lambda_l2=0.01):\n",
    "    train_loader = dataloaders['train']\n",
    "    val_loader = dataloaders['val']\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch}/{num_epochs - 1}\")\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Add L2 regularization\n",
    "            l2_loss = l2_regularization(model, lambda_l2)\n",
    "            total_loss = loss + l2_loss  # Add the L2 regularization loss\n",
    "\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_preds += torch.sum(preds == labels)\n",
    "            total_preds += labels.size(0)\n",
    "            running_loss += total_loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = correct_preds.double() / total_preds\n",
    "        print(f\"Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "            best_acc = val_acc\n",
    "            best_model_wts = model.state_dict()\n",
    "\n",
    "    print(f\"Best val Acc: {best_acc:.4f}\")\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with L2 Regularization (Weight Decay in Optimizer)\n",
      "Epoch 0/9\n",
      "----------\n",
      "Train Loss: 0.7395 Acc: 0.4875\n",
      "Val Accuracy: 0.5310\n",
      "Epoch 1/9\n",
      "----------\n",
      "Train Loss: 0.6885 Acc: 0.5410\n",
      "Val Accuracy: 0.5740\n",
      "Epoch 2/9\n",
      "----------\n",
      "Train Loss: 0.6831 Acc: 0.5650\n",
      "Val Accuracy: 0.5390\n",
      "Epoch 3/9\n",
      "----------\n",
      "Train Loss: 0.6754 Acc: 0.5735\n",
      "Val Accuracy: 0.6070\n",
      "Epoch 4/9\n",
      "----------\n",
      "Train Loss: 0.6572 Acc: 0.6055\n",
      "Val Accuracy: 0.5750\n",
      "Epoch 5/9\n",
      "----------\n",
      "Train Loss: 0.6418 Acc: 0.6385\n",
      "Val Accuracy: 0.6080\n",
      "Epoch 6/9\n",
      "----------\n",
      "Train Loss: 0.6085 Acc: 0.6665\n",
      "Val Accuracy: 0.5950\n",
      "Epoch 7/9\n",
      "----------\n",
      "Train Loss: 0.5594 Acc: 0.7210\n",
      "Val Accuracy: 0.6850\n",
      "Epoch 8/9\n",
      "----------\n",
      "Train Loss: 0.4990 Acc: 0.7580\n",
      "Val Accuracy: 0.6490\n",
      "Epoch 9/9\n",
      "----------\n",
      "Train Loss: 0.4480 Acc: 0.7945\n",
      "Val Accuracy: 0.6590\n",
      "Best val Acc: 0.6850\n"
     ]
    }
   ],
   "source": [
    "# Model, Loss function, and Optimizer\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train model with L2 regularization using optimizer's weight decay\n",
    "print(\"Training with L2 Regularization (Weight Decay in Optimizer)\")\n",
    "optimizer_with_l2 = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0005)  # Using weight decay\n",
    "model_with_l2_optimizer = train_model(model, dataloaders_without_aug, criterion, optimizer_with_l2, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with L2 Regularization (Manual Loop for L2 Norm)\n",
      "Epoch 0/9\n",
      "----------\n",
      "Train Loss: 0.8305 Acc: 0.5105\n",
      "Val Accuracy: 0.5460\n",
      "Epoch 1/9\n",
      "----------\n",
      "Train Loss: 0.7296 Acc: 0.5675\n",
      "Val Accuracy: 0.5760\n",
      "Epoch 2/9\n",
      "----------\n",
      "Train Loss: 0.7066 Acc: 0.5845\n",
      "Val Accuracy: 0.5900\n",
      "Epoch 3/9\n",
      "----------\n",
      "Train Loss: 0.6856 Acc: 0.6085\n",
      "Val Accuracy: 0.5830\n",
      "Epoch 4/9\n",
      "----------\n",
      "Train Loss: 0.6794 Acc: 0.6205\n",
      "Val Accuracy: 0.5990\n",
      "Epoch 5/9\n",
      "----------\n",
      "Train Loss: 0.6646 Acc: 0.6420\n",
      "Val Accuracy: 0.6130\n",
      "Epoch 6/9\n",
      "----------\n",
      "Train Loss: 0.6544 Acc: 0.6575\n",
      "Val Accuracy: 0.6000\n",
      "Epoch 7/9\n",
      "----------\n",
      "Train Loss: 0.6392 Acc: 0.6765\n",
      "Val Accuracy: 0.6090\n",
      "Epoch 8/9\n",
      "----------\n",
      "Train Loss: 0.5992 Acc: 0.7185\n",
      "Val Accuracy: 0.6090\n",
      "Epoch 9/9\n",
      "----------\n",
      "Train Loss: 0.5805 Acc: 0.7350\n",
      "Val Accuracy: 0.6480\n",
      "Best val Acc: 0.6480\n"
     ]
    }
   ],
   "source": [
    "# Model, Loss function, and Optimizer\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "#Train model with L2 regularization using manual loop\n",
    "print(\"\\nTraining with L2 Regularization (Manual Loop for L2 Norm)\")\n",
    "model_with_l2_manual = train_model_with_l2_regularization(model, dataloaders_without_aug, criterion, optimizer, num_epochs=10, lambda_l2=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2\n",
    "L1 Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_regularization(model, lambda_l1=0.01):\n",
    "    l1_norm = 0.0\n",
    "    for param in model.parameters():\n",
    "        if param.dim() > 1:  \n",
    "            l1_norm += torch.sum(torch.abs(param)) \n",
    "    return lambda_l1 * l1_norm\n",
    "\n",
    "\n",
    "# Modified train_model function to include L2 regularization manually\n",
    "def train_model_with_l1_regularization(model, dataloaders, criterion, optimizer, num_epochs=10, lambda_l1=0.01):\n",
    "    train_loader = dataloaders['train']\n",
    "    val_loader = dataloaders['val']\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch}/{num_epochs - 1}\")\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            l1_loss = l1_regularization(model, lambda_l1)\n",
    "            total_loss = loss + l1_loss \n",
    "\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_preds += torch.sum(preds == labels)\n",
    "            total_preds += labels.size(0)\n",
    "            running_loss += total_loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = correct_preds.double() / total_preds\n",
    "        print(f\"Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct_preds += torch.sum(preds == labels)\n",
    "                total_preds += labels.size(0)\n",
    "\n",
    "        val_acc = correct_preds.double() / total_preds\n",
    "        print(f\"Val Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "        # Deep copy the model\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_wts = model.state_dict()\n",
    "\n",
    "    print(f\"Best val Acc: {best_acc:.4f}\")\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with L1 Regularization (Manual Loop for L1 Norm)\n",
      "Epoch 0/9\n",
      "----------\n",
      "Train Loss: 7.0022 Acc: 0.4935\n",
      "Val Accuracy: 0.5000\n",
      "Epoch 1/9\n",
      "----------\n",
      "Train Loss: 2.6167 Acc: 0.5000\n",
      "Val Accuracy: 0.5000\n",
      "Epoch 2/9\n",
      "----------\n",
      "Train Loss: 2.3833 Acc: 0.5000\n",
      "Val Accuracy: 0.5000\n",
      "Epoch 3/9\n",
      "----------\n",
      "Train Loss: 2.3537 Acc: 0.4830\n",
      "Val Accuracy: 0.5000\n",
      "Epoch 4/9\n",
      "----------\n",
      "Train Loss: 2.3401 Acc: 0.4920\n",
      "Val Accuracy: 0.5000\n",
      "Epoch 5/9\n",
      "----------\n",
      "Train Loss: 2.3463 Acc: 0.4980\n",
      "Val Accuracy: 0.5000\n",
      "Epoch 6/9\n",
      "----------\n",
      "Train Loss: 2.3365 Acc: 0.5000\n",
      "Val Accuracy: 0.5000\n",
      "Epoch 7/9\n",
      "----------\n",
      "Train Loss: 2.3363 Acc: 0.4790\n",
      "Val Accuracy: 0.5000\n",
      "Epoch 8/9\n",
      "----------\n",
      "Train Loss: 2.3391 Acc: 0.5020\n",
      "Val Accuracy: 0.5000\n",
      "Epoch 9/9\n",
      "----------\n",
      "Train Loss: 2.3360 Acc: 0.5000\n",
      "Val Accuracy: 0.5000\n",
      "Best val Acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Model, Loss function, and Optimizer\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"\\nTraining with L1 Regularization (Manual Loop for L1 Norm)\")\n",
    "model_with_l1_manual = train_model_with_l1_regularization(model, dataloaders_without_aug, criterion, optimizer, num_epochs=10, lambda_l1=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3\n",
    "Dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Dropout\n",
      "Epoch 0/9\n",
      "----------\n",
      "Train Loss: 0.7917 Acc: 0.4990\n",
      "Val Accuracy: 0.5000\n",
      "Epoch 1/9\n",
      "----------\n",
      "Train Loss: 0.6929 Acc: 0.5035\n",
      "Val Accuracy: 0.5050\n",
      "Epoch 2/9\n",
      "----------\n",
      "Train Loss: 0.6930 Acc: 0.5140\n",
      "Val Accuracy: 0.5080\n",
      "Epoch 3/9\n",
      "----------\n",
      "Train Loss: 0.6926 Acc: 0.5295\n",
      "Val Accuracy: 0.5550\n",
      "Epoch 4/9\n",
      "----------\n",
      "Train Loss: 0.6860 Acc: 0.5815\n",
      "Val Accuracy: 0.5320\n",
      "Epoch 5/9\n",
      "----------\n",
      "Train Loss: 0.6738 Acc: 0.5870\n",
      "Val Accuracy: 0.5680\n",
      "Epoch 6/9\n",
      "----------\n",
      "Train Loss: 0.6703 Acc: 0.6025\n",
      "Val Accuracy: 0.6150\n",
      "Epoch 7/9\n",
      "----------\n",
      "Train Loss: 0.6246 Acc: 0.6645\n",
      "Val Accuracy: 0.6320\n",
      "Epoch 8/9\n",
      "----------\n",
      "Train Loss: 0.6057 Acc: 0.6685\n",
      "Val Accuracy: 0.5720\n",
      "Epoch 9/9\n",
      "----------\n",
      "Train Loss: 0.6157 Acc: 0.6700\n",
      "Val Accuracy: 0.6390\n",
      "Best val Acc: 0.6390\n"
     ]
    }
   ],
   "source": [
    "class DropoutSimpleCNN(nn.Module):\n",
    "    def __init__(self, dropout_prob=0.5):\n",
    "        super(DropoutSimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(28 * 28 * 64, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = DropoutSimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Training with Dropout\")\n",
    "model_with_dropout = train_model(model, dataloaders_without_aug, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4\n",
    "Custom Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDropout(nn.Module):\n",
    "    def __init__(self, p: float = 0.5):\n",
    "        super(CustomDropout, self).__init__()\n",
    "        self.p = p\n",
    "        self.training = True \n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            mask = torch.bernoulli(torch.full_like(x, 1 - self.p))  \n",
    "            x = x * mask\n",
    "            x = x / (1 - self.p) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDropoutSimpleCNN(nn.Module):\n",
    "    def __init__(self, dropout_prob=0.5):\n",
    "        super(CustomDropoutSimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(28 * 28 * 64, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "\n",
    "        self.dropout = CustomDropoutSimpleCNN(dropout_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = CustomDropoutSimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Training with Dropout\")\n",
    "model_with_dropout = train_model(model, dataloaders_without_aug, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5\n",
    "Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_loss = float(\"inf\")\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "        self.best_model_wts = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.best_model_wts = model.state_dict()\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "    def restore_best_weights(self, model):\n",
    "        if self.best_model_wts is not None:\n",
    "            model.load_state_dict(self.best_model_wts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with early stopping\n",
    "def train_model_with_early_stopping(model, dataloaders, criterion, optimizer, num_epochs=10, patience=5):\n",
    "    train_loader = dataloaders['train']\n",
    "    val_loader = dataloaders['val']\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "    early_stopping = EarlyStopping(patience=patience)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch}/{num_epochs - 1}\")\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_preds += torch.sum(preds == labels)\n",
    "            total_preds += labels.size(0)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = correct_preds.double() / total_preds\n",
    "        print(f\"Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "        val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                \n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct_preds += torch.sum(preds == labels)\n",
    "                total_preds += labels.size(0)\n",
    "\n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_acc = correct_preds.double() / total_preds\n",
    "        print(f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "\n",
    "        # Early stopping check\n",
    "        early_stopping(val_loss, model)\n",
    "        \n",
    "        # Stop training if early stopping criteria are met\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "    # Load best model weights and return the model\n",
    "    early_stopping.restore_best_weights(model)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Early Stopping\n",
      "Epoch 0/19\n",
      "----------\n",
      "Train Loss: 0.7856 Acc: 0.4980\n",
      "Val Loss: 0.6874 Acc: 0.5840\n",
      "Epoch 1/19\n",
      "----------\n",
      "Train Loss: 0.6810 Acc: 0.5820\n",
      "Val Loss: 0.6772 Acc: 0.5700\n",
      "Epoch 2/19\n",
      "----------\n",
      "Train Loss: 0.6473 Acc: 0.6385\n",
      "Val Loss: 0.6698 Acc: 0.6080\n",
      "Epoch 3/19\n",
      "----------\n",
      "Train Loss: 0.6059 Acc: 0.6860\n",
      "Val Loss: 0.6399 Acc: 0.6400\n",
      "Epoch 4/19\n",
      "----------\n",
      "Train Loss: 0.5436 Acc: 0.7420\n",
      "Val Loss: 0.9029 Acc: 0.5840\n",
      "Epoch 5/19\n",
      "----------\n",
      "Train Loss: 0.5278 Acc: 0.7405\n",
      "Val Loss: 0.6200 Acc: 0.7000\n",
      "Epoch 6/19\n",
      "----------\n",
      "Train Loss: 0.4665 Acc: 0.7825\n",
      "Val Loss: 0.6349 Acc: 0.6780\n",
      "Epoch 7/19\n",
      "----------\n",
      "Train Loss: 0.3952 Acc: 0.8235\n",
      "Val Loss: 0.7291 Acc: 0.6880\n",
      "Epoch 8/19\n",
      "----------\n",
      "Train Loss: 0.3236 Acc: 0.8560\n",
      "Val Loss: 0.7082 Acc: 0.6920\n",
      "Epoch 9/19\n",
      "----------\n",
      "Train Loss: 0.2555 Acc: 0.8905\n",
      "Val Loss: 0.8375 Acc: 0.6910\n",
      "Epoch 10/19\n",
      "----------\n",
      "Train Loss: 0.1771 Acc: 0.9285\n",
      "Val Loss: 0.8701 Acc: 0.6810\n",
      "Early stopping at epoch 10\n"
     ]
    }
   ],
   "source": [
    "# Set device to CUDA if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model with early stopping\n",
    "print(\"Training with Early Stopping\")\n",
    "model_with_early_stopping = train_model_with_early_stopping(model, dataloaders_without_aug, criterion, optimizer, num_epochs=20, patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training without Early Stopping\n",
      "Epoch 0/19\n",
      "----------\n",
      "Train Loss: 0.1247 Acc: 0.9600\n",
      "Val Accuracy: 0.6650\n",
      "Epoch 1/19\n",
      "----------\n",
      "Train Loss: 0.0583 Acc: 0.9810\n",
      "Val Accuracy: 0.6780\n",
      "Epoch 2/19\n",
      "----------\n",
      "Train Loss: 0.0518 Acc: 0.9835\n",
      "Val Accuracy: 0.6730\n",
      "Epoch 3/19\n",
      "----------\n",
      "Train Loss: 0.0351 Acc: 0.9870\n",
      "Val Accuracy: 0.6520\n",
      "Epoch 4/19\n",
      "----------\n",
      "Train Loss: 0.0353 Acc: 0.9880\n",
      "Val Accuracy: 0.6650\n",
      "Epoch 5/19\n",
      "----------\n",
      "Train Loss: 0.0154 Acc: 0.9970\n",
      "Val Accuracy: 0.6600\n",
      "Epoch 6/19\n",
      "----------\n",
      "Train Loss: 0.0065 Acc: 1.0000\n",
      "Val Accuracy: 0.6680\n",
      "Epoch 7/19\n",
      "----------\n",
      "Train Loss: 0.0027 Acc: 1.0000\n",
      "Val Accuracy: 0.6540\n",
      "Epoch 8/19\n",
      "----------\n",
      "Train Loss: 0.0014 Acc: 1.0000\n",
      "Val Accuracy: 0.6590\n",
      "Epoch 9/19\n",
      "----------\n",
      "Train Loss: 0.0010 Acc: 1.0000\n",
      "Val Accuracy: 0.6620\n",
      "Epoch 10/19\n",
      "----------\n",
      "Train Loss: 0.0008 Acc: 1.0000\n",
      "Val Accuracy: 0.6680\n",
      "Epoch 11/19\n",
      "----------\n",
      "Train Loss: 0.0006 Acc: 1.0000\n",
      "Val Accuracy: 0.6690\n",
      "Epoch 12/19\n",
      "----------\n",
      "Train Loss: 0.0005 Acc: 1.0000\n",
      "Val Accuracy: 0.6630\n",
      "Epoch 13/19\n",
      "----------\n",
      "Train Loss: 0.0005 Acc: 1.0000\n",
      "Val Accuracy: 0.6680\n",
      "Epoch 14/19\n",
      "----------\n",
      "Train Loss: 0.0004 Acc: 1.0000\n",
      "Val Accuracy: 0.6660\n",
      "Epoch 15/19\n",
      "----------\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Accuracy: 0.6590\n",
      "Epoch 16/19\n",
      "----------\n",
      "Train Loss: 0.0003 Acc: 1.0000\n",
      "Val Accuracy: 0.6690\n",
      "Epoch 17/19\n",
      "----------\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Accuracy: 0.6660\n",
      "Epoch 18/19\n",
      "----------\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Accuracy: 0.6630\n",
      "Epoch 19/19\n",
      "----------\n",
      "Train Loss: 0.0002 Acc: 1.0000\n",
      "Val Accuracy: 0.6690\n",
      "Best val Acc: 0.6780\n"
     ]
    }
   ],
   "source": [
    "# Train the model without early stopping\n",
    "print(\"Training without Early Stopping\")\n",
    "model_without_early_stopping = train_model(model, dataloaders_without_aug, criterion, optimizer, num_epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the models on validation set\n",
    "print(\"Evaluating model with early stopping:\")\n",
    "eval_model(model_with_early_stopping, val_loader)\n",
    "\n",
    "print(\"Evaluating model without early stopping:\")\n",
    "eval_model(model_without_early_stopping, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
