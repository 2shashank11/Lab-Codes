{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a great game</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the election was over</td>\n",
       "      <td>NS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>very clean match</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a clean but forgettable game</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it was a close election</td>\n",
       "      <td>NS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           text tag\n",
       "0                  a great game   S\n",
       "1         the election was over  NS\n",
       "2              very clean match   S\n",
       "3  a clean but forgettable game   S\n",
       "4       it was a close election  NS"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"text\": [\n",
    "        \"a great game\",\n",
    "        \"the election was over\",\n",
    "        \"very clean match\",\n",
    "        \"a clean but forgettable game\",\n",
    "        \"it was a close election\"\n",
    "    ],\n",
    "    \"tag\": [\"S\", \"NS\", \"S\", \"S\", \"NS\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.vocab = set()\n",
    "        self.label_count = defaultdict(int)\n",
    "        self.labelled_word_count = defaultdict(lambda: defaultdict(int))\n",
    "        self.word_count = defaultdict(int)\n",
    "        self.class_probs = {}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for text, label in zip(X, y):\n",
    "            words = text.split()\n",
    "            self.label_count[label] += 1\n",
    "\n",
    "            for word in words:\n",
    "                self.vocab.add(word)\n",
    "                self.labelled_word_count[label][word] += 1\n",
    "                self.word_count[word] += 1\n",
    "\n",
    "        total_count = sum(self.label_count.values())\n",
    "        for label, count in self.label_count.items():\n",
    "            self.class_probs[label] = count/total_count\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = {}\n",
    "\n",
    "        for text in X:\n",
    "            words = text.split()\n",
    "\n",
    "            class_scores = {}\n",
    "\n",
    "            for label in self.label_count.keys():\n",
    "                class_score = self.class_probs[label] # np.log(self.class_probs[label])\n",
    "\n",
    "                for word in words:\n",
    "                    word_count = self.labelled_word_count[label][word]\n",
    "                    total_count = self.label_count[label]+len(self.vocab)\n",
    "\n",
    "                    class_score *=  (1+word_count)/(total_count)\n",
    "                    class_scores[label] = class_score\n",
    "            \n",
    "            pred, label = 0, None\n",
    "            for i, j in class_scores.items():\n",
    "                if(j>pred):\n",
    "                    pred=j\n",
    "                    label=i\n",
    "            predictions[label]=pred\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'S': 0.0003663749236718909}\n"
     ]
    }
   ],
   "source": [
    "nb = NaiveBayesClassifier()\n",
    "\n",
    "X = df['text'].values\n",
    "y = df['tag'].values\n",
    "\n",
    "nb.fit(X, y)\n",
    "\n",
    "input = [\"a very close game\", \"game not election\"]\n",
    "\n",
    "y_pred = nb.predict(input)\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
